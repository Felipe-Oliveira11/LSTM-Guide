{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Glove-Embedding.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "igfWx0DA0P5K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "8919f3fb-26e6-4e69-b20b-b31d52f36d38"
      },
      "source": [
        "import os \n",
        "import re\n",
        "import string\n",
        "import random \n",
        "import time \n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns \n",
        "\n",
        "%matplotlib inline \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import tensorflow as tf \n",
        "from tensorflow import keras \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.layers import Flatten, Embedding, Dropout\n",
        "from tensorflow.keras.layers import Conv1D, SpatialDropout1D\n",
        "from tensorflow.keras.layers import Dense, Input \n",
        "from tensorflow.keras.layers import GlobalMaxPooling2D, GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers import LSTM, Dropout, GRU, Bidirectional"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DG3jdL0j1Hei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4DL0viC1H71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/Deep Learning - Projetos/Classificação de Texto - Twitter /training.1600000.processed.noemoticon.csv'\n",
        "data = pd.read_csv(path, encoding='latin', header=None)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjb6HfAA1J2o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "772a2933-9556-4bb8-cde9-2109f14c92f4"
      },
      "source": [
        "data.columns = ['sentiment', 'id', 'date', 'query', 'user_id', 'text']\n",
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>query</th>\n",
              "      <th>user_id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment  ...                                               text\n",
              "0          0  ...  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1          0  ...  is upset that he can't update his Facebook by ...\n",
              "2          0  ...  @Kenichan I dived many times for the ball. Man...\n",
              "3          0  ...    my whole body feels itchy and like its on fire \n",
              "4          0  ...  @nationwideclass no, it's not behaving at all....\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2KIL5mi1MDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.drop(['id', 'date', 'query', 'user_id'], axis=1, inplace=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gYdh4kl3tHy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8342d71a-f0b9-41d3-e6ff-8da41cb47310"
      },
      "source": [
        "# Regex sub\n",
        "\n",
        "text_cleaning_re = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
        "texto = 'Felipe@ foi a escola@#4 ontem*['\n",
        "\n",
        "limpeza = re.sub(text_cleaning_re ,' ', texto)\n",
        "\n",
        "print(texto,'\\n',limpeza)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Felipe@ foi a escola@#4 ontem*[ \n",
            " Felipe foi a escola  ontem \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODrmpNHF1-hW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stemmer and Stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "stemmer = SnowballStemmer('english')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEp9Ed8b2ApO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_cleaning_re = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
        "\n",
        "\n",
        "def preprocess(text, stem=False):\n",
        "  text = re.sub(text_cleaning_re, ' ', str(text).lower()).strip()\n",
        "  tokens = []\n",
        "  for token in text.split():\n",
        "    if token not in stop_words:\n",
        "      if stem:\n",
        "        tokens.append(stemmer.stem(token))\n",
        "      else: \n",
        "        tokens.append(token)\n",
        "  return \" \".join(tokens)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbgs_vwQ6riw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['text'] = data['text'].apply(lambda x: preprocess(x, stem=False))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WbZAvxk6z1W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "735bc5c1-a34e-473e-f87e-02e457beda40"
      },
      "source": [
        "# train and test \n",
        "\n",
        "X = data['text']\n",
        "y = data['sentiment']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=42)\n",
        "\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_test = encoder.fit_transform(y_test)\n",
        "\n",
        "print('Train: {}'.format(X_train.shape))\n",
        "print('Teste: {}'.format(X_test.shape))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: (1120000,)\n",
            "Teste: (480000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33jOLj227Q16",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bad9c9c8-1f0a-4217-cf0a-9f971b454540"
      },
      "source": [
        "# Tokenizador \n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# Índice de palavras \n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1\n",
        "print('Vocabulary size: {}'.format(vocab_size))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size: 266578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbpak2Z2Asmo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0ee1c1d4-3011-4cc1-fd6f-09ff8887b14a"
      },
      "source": [
        "max_sequence_length = 50 \n",
        "\n",
        "sequences_train = tokenizer.texts_to_sequences(X_train)\n",
        "sequences_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train = pad_sequences(sequences_train, maxlen=max_sequence_length, padding='post')\n",
        "X_test = pad_sequences(sequences_test, maxlen=max_sequence_length, padding='post')\n",
        "\n",
        "\n",
        "print('Maior Sequência: {}'.format(len(max(data.text))))\n",
        "print('Sequência definida: {}'.format(max_sequence_length))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maior Sequência: 58\n",
            "Sequência definida: 50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVoI43MVPk99",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "a4828b10-1f15-4d72-c3d2-97b013246c42"
      },
      "source": [
        "# identifiando sentimentos [Positivo = 1 | Negativo = 0]\n",
        "for x,y in zip(y_train[0:3], X_train[0:3]):\n",
        "  print('Sentiment {} ----- {}'.format(x,y))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentiment 1 ----- [96797  1485  5501   300  1485   201  1407   386   520  6258    25   134\n",
            "  1014  2632    20   748   201   599     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0]\n",
            "Sentiment 0 ----- [  136 65783 39168  1390   254  3908   496  2087  1276     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0]\n",
            "Sentiment 0 ----- [   23   194   114 28091  6007   488    28   200   146 28091     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ucQHdShB0Ll",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "82ca2059-cf40-448d-acf2-d1ca7561b215"
      },
      "source": [
        "# índice de palavras\n",
        "word_index"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'good': 1,\n",
              " 'day': 2,\n",
              " 'get': 3,\n",
              " 'like': 4,\n",
              " 'go': 5,\n",
              " 'quot': 6,\n",
              " 'today': 7,\n",
              " 'work': 8,\n",
              " 'going': 9,\n",
              " 'love': 10,\n",
              " 'got': 11,\n",
              " 'lol': 12,\n",
              " 'time': 13,\n",
              " 'back': 14,\n",
              " 'u': 15,\n",
              " 'one': 16,\n",
              " 'know': 17,\n",
              " 'im': 18,\n",
              " 'really': 19,\n",
              " 'amp': 20,\n",
              " 'see': 21,\n",
              " 'night': 22,\n",
              " 'still': 23,\n",
              " '2': 24,\n",
              " 'well': 25,\n",
              " 'new': 26,\n",
              " 'want': 27,\n",
              " 'think': 28,\n",
              " 'home': 29,\n",
              " 'thanks': 30,\n",
              " 'oh': 31,\n",
              " 'much': 32,\n",
              " 'miss': 33,\n",
              " 'need': 34,\n",
              " 'last': 35,\n",
              " 'morning': 36,\n",
              " 'tomorrow': 37,\n",
              " 'hope': 38,\n",
              " 'great': 39,\n",
              " 'twitter': 40,\n",
              " '3': 41,\n",
              " 'haha': 42,\n",
              " 'feel': 43,\n",
              " 'sad': 44,\n",
              " 'fun': 45,\n",
              " 'wish': 46,\n",
              " 'sleep': 47,\n",
              " 'right': 48,\n",
              " 'would': 49,\n",
              " 'bad': 50,\n",
              " 'happy': 51,\n",
              " 'sorry': 52,\n",
              " 'tonight': 53,\n",
              " 'come': 54,\n",
              " 'make': 55,\n",
              " 'way': 56,\n",
              " 'getting': 57,\n",
              " 'gonna': 58,\n",
              " 'though': 59,\n",
              " 'nice': 60,\n",
              " 'better': 61,\n",
              " 'watching': 62,\n",
              " 'yeah': 63,\n",
              " 'bed': 64,\n",
              " 'wait': 65,\n",
              " 'could': 66,\n",
              " 'week': 67,\n",
              " 'people': 68,\n",
              " 'school': 69,\n",
              " 'hate': 70,\n",
              " 'hey': 71,\n",
              " 'days': 72,\n",
              " 'even': 73,\n",
              " '4': 74,\n",
              " 'next': 75,\n",
              " 'yes': 76,\n",
              " 'weekend': 77,\n",
              " 'lt': 78,\n",
              " 'dont': 79,\n",
              " 'awesome': 80,\n",
              " 'thank': 81,\n",
              " 'soon': 82,\n",
              " 'never': 83,\n",
              " 'cant': 84,\n",
              " 'long': 85,\n",
              " 'take': 86,\n",
              " 'little': 87,\n",
              " 'first': 88,\n",
              " 'working': 89,\n",
              " 'wanna': 90,\n",
              " 'please': 91,\n",
              " 'say': 92,\n",
              " 'everyone': 93,\n",
              " 'best': 94,\n",
              " 'life': 95,\n",
              " 'ok': 96,\n",
              " 'tired': 97,\n",
              " 'show': 98,\n",
              " 'sick': 99,\n",
              " 'watch': 100,\n",
              " '1': 101,\n",
              " 'done': 102,\n",
              " 'feeling': 103,\n",
              " 'let': 104,\n",
              " 'always': 105,\n",
              " 'thing': 106,\n",
              " 'x': 107,\n",
              " 'sure': 108,\n",
              " 'already': 109,\n",
              " 'cool': 110,\n",
              " 'friends': 111,\n",
              " 'another': 112,\n",
              " 'us': 113,\n",
              " 'find': 114,\n",
              " 'something': 115,\n",
              " 'guys': 116,\n",
              " 'man': 117,\n",
              " 'ready': 118,\n",
              " 'made': 119,\n",
              " 'yay': 120,\n",
              " 'looking': 121,\n",
              " 'yet': 122,\n",
              " 'went': 123,\n",
              " 'phone': 124,\n",
              " 'look': 125,\n",
              " 'hours': 126,\n",
              " 'ur': 127,\n",
              " 'house': 128,\n",
              " 'movie': 129,\n",
              " 'ever': 130,\n",
              " 'pretty': 131,\n",
              " 'trying': 132,\n",
              " 'n': 133,\n",
              " 'maybe': 134,\n",
              " 'away': 135,\n",
              " 'omg': 136,\n",
              " 'summer': 137,\n",
              " 'tweet': 138,\n",
              " 'finally': 139,\n",
              " '5': 140,\n",
              " 'old': 141,\n",
              " 'damn': 142,\n",
              " 'early': 143,\n",
              " 'help': 144,\n",
              " 'amazing': 145,\n",
              " 'follow': 146,\n",
              " 'things': 147,\n",
              " 'someone': 148,\n",
              " 'left': 149,\n",
              " 'lost': 150,\n",
              " 'guess': 151,\n",
              " 'keep': 152,\n",
              " 'friend': 153,\n",
              " 'wow': 154,\n",
              " 'thought': 155,\n",
              " 'bit': 156,\n",
              " 'big': 157,\n",
              " 'year': 158,\n",
              " 'sucks': 159,\n",
              " 'nothing': 160,\n",
              " 'hot': 161,\n",
              " 'missed': 162,\n",
              " 'rain': 163,\n",
              " 'ya': 164,\n",
              " 'bored': 165,\n",
              " 'girl': 166,\n",
              " 'birthday': 167,\n",
              " 'also': 168,\n",
              " 'try': 169,\n",
              " 'glad': 170,\n",
              " 'coming': 171,\n",
              " 'start': 172,\n",
              " 'looks': 173,\n",
              " 'baby': 174,\n",
              " 'tell': 175,\n",
              " 'two': 176,\n",
              " 'weather': 177,\n",
              " 'live': 178,\n",
              " 'later': 179,\n",
              " 'sun': 180,\n",
              " 'w': 181,\n",
              " 'song': 182,\n",
              " 'actually': 183,\n",
              " 'ugh': 184,\n",
              " 'stuff': 185,\n",
              " 'hear': 186,\n",
              " 'saw': 187,\n",
              " 'party': 188,\n",
              " 'excited': 189,\n",
              " 'makes': 190,\n",
              " 'hard': 191,\n",
              " 'might': 192,\n",
              " 'play': 193,\n",
              " 'waiting': 194,\n",
              " 'game': 195,\n",
              " 'yesterday': 196,\n",
              " 'god': 197,\n",
              " 'thats': 198,\n",
              " 'said': 199,\n",
              " 'since': 200,\n",
              " 'world': 201,\n",
              " 'hi': 202,\n",
              " 'gotta': 203,\n",
              " 'lot': 204,\n",
              " 'late': 205,\n",
              " 'mom': 206,\n",
              " 'around': 207,\n",
              " 'car': 208,\n",
              " 'music': 209,\n",
              " 'b': 210,\n",
              " 'many': 211,\n",
              " 'head': 212,\n",
              " 'found': 213,\n",
              " 'sounds': 214,\n",
              " 'luck': 215,\n",
              " 'check': 216,\n",
              " 'friday': 217,\n",
              " 'r': 218,\n",
              " 'must': 219,\n",
              " 'call': 220,\n",
              " 'cold': 221,\n",
              " 'job': 222,\n",
              " 'read': 223,\n",
              " 'give': 224,\n",
              " 'aww': 225,\n",
              " 'making': 226,\n",
              " 'beautiful': 227,\n",
              " 'sunday': 228,\n",
              " 'talk': 229,\n",
              " 'gone': 230,\n",
              " 'may': 231,\n",
              " 'put': 232,\n",
              " 'monday': 233,\n",
              " 'com': 234,\n",
              " 'missing': 235,\n",
              " 'anything': 236,\n",
              " 'poor': 237,\n",
              " 'woke': 238,\n",
              " 'least': 239,\n",
              " 'stop': 240,\n",
              " 'almost': 241,\n",
              " 'hair': 242,\n",
              " 'okay': 243,\n",
              " 'use': 244,\n",
              " 'tho': 245,\n",
              " 'till': 246,\n",
              " 'leave': 247,\n",
              " 'lunch': 248,\n",
              " 'free': 249,\n",
              " 'times': 250,\n",
              " 'cute': 251,\n",
              " 'family': 252,\n",
              " 'mean': 253,\n",
              " 'food': 254,\n",
              " 'far': 255,\n",
              " '10': 256,\n",
              " 'listening': 257,\n",
              " 'dinner': 258,\n",
              " 'eat': 259,\n",
              " 'iphone': 260,\n",
              " 'hurts': 261,\n",
              " 'funny': 262,\n",
              " 'end': 263,\n",
              " 'hour': 264,\n",
              " 'enjoy': 265,\n",
              " 'wanted': 266,\n",
              " 'everything': 267,\n",
              " 'gt': 268,\n",
              " 'finished': 269,\n",
              " 'shit': 270,\n",
              " 'followers': 271,\n",
              " 'playing': 272,\n",
              " 'believe': 273,\n",
              " 'anyone': 274,\n",
              " 'sweet': 275,\n",
              " 'welcome': 276,\n",
              " 'thinking': 277,\n",
              " 'without': 278,\n",
              " '6': 279,\n",
              " 'cause': 280,\n",
              " 'forward': 281,\n",
              " 'video': 282,\n",
              " 'totally': 283,\n",
              " 'mine': 284,\n",
              " 'stupid': 285,\n",
              " 'outside': 286,\n",
              " 'real': 287,\n",
              " 'hahaha': 288,\n",
              " 'coffee': 289,\n",
              " 'buy': 290,\n",
              " 'enough': 291,\n",
              " 'ill': 292,\n",
              " 'wrong': 293,\n",
              " 'p': 294,\n",
              " 'anymore': 295,\n",
              " 'probably': 296,\n",
              " 'every': 297,\n",
              " 'didnt': 298,\n",
              " 'room': 299,\n",
              " 'place': 300,\n",
              " 'tv': 301,\n",
              " 'ha': 302,\n",
              " 'weeks': 303,\n",
              " 'tweets': 304,\n",
              " 'eating': 305,\n",
              " 'following': 306,\n",
              " 'busy': 307,\n",
              " 'money': 308,\n",
              " 'c': 309,\n",
              " 'win': 310,\n",
              " 'stay': 311,\n",
              " 'xx': 312,\n",
              " 'wants': 313,\n",
              " 'dad': 314,\n",
              " 'sooo': 315,\n",
              " 'saturday': 316,\n",
              " 'whole': 317,\n",
              " '30': 318,\n",
              " 'class': 319,\n",
              " 'lovely': 320,\n",
              " 'seen': 321,\n",
              " 'pic': 322,\n",
              " '8': 323,\n",
              " 'says': 324,\n",
              " 'came': 325,\n",
              " 'taking': 326,\n",
              " 'kinda': 327,\n",
              " '7': 328,\n",
              " 'beach': 329,\n",
              " 'kids': 330,\n",
              " 'hopefully': 331,\n",
              " 'crazy': 332,\n",
              " 'exam': 333,\n",
              " 'took': 334,\n",
              " 'headache': 335,\n",
              " 'super': 336,\n",
              " 'news': 337,\n",
              " 'name': 338,\n",
              " 'half': 339,\n",
              " 'guy': 340,\n",
              " 'hello': 341,\n",
              " 'hell': 342,\n",
              " 'post': 343,\n",
              " 'awww': 344,\n",
              " 'idea': 345,\n",
              " 'book': 346,\n",
              " 'true': 347,\n",
              " 'years': 348,\n",
              " 'forgot': 349,\n",
              " 'face': 350,\n",
              " 'goodnight': 351,\n",
              " 'run': 352,\n",
              " 'able': 353,\n",
              " 'lots': 354,\n",
              " 'ago': 355,\n",
              " 'else': 356,\n",
              " 'shopping': 357,\n",
              " 'rest': 358,\n",
              " 'send': 359,\n",
              " 'either': 360,\n",
              " 'full': 361,\n",
              " 'meet': 362,\n",
              " 'reading': 363,\n",
              " 'sitting': 364,\n",
              " 'leaving': 365,\n",
              " 'used': 366,\n",
              " 'computer': 367,\n",
              " 'boo': 368,\n",
              " 'ah': 369,\n",
              " 'girls': 370,\n",
              " 'soo': 371,\n",
              " 'hurt': 372,\n",
              " 'cuz': 373,\n",
              " 'feels': 374,\n",
              " 'raining': 375,\n",
              " 'seems': 376,\n",
              " 'fuck': 377,\n",
              " 'remember': 378,\n",
              " 'stuck': 379,\n",
              " 'alone': 380,\n",
              " 'blog': 381,\n",
              " 'dog': 382,\n",
              " 'hehe': 383,\n",
              " 'talking': 384,\n",
              " 'needs': 385,\n",
              " 'trip': 386,\n",
              " 'btw': 387,\n",
              " 'tried': 388,\n",
              " 'heard': 389,\n",
              " 'hit': 390,\n",
              " 'heart': 391,\n",
              " 'office': 392,\n",
              " 'watched': 393,\n",
              " 'internet': 394,\n",
              " 'www': 395,\n",
              " 'course': 396,\n",
              " 'mind': 397,\n",
              " 'kind': 398,\n",
              " 'started': 399,\n",
              " 'part': 400,\n",
              " 'seeing': 401,\n",
              " 'wont': 402,\n",
              " 'boy': 403,\n",
              " 'using': 404,\n",
              " 'picture': 405,\n",
              " 'quite': 406,\n",
              " 'break': 407,\n",
              " 'add': 408,\n",
              " 'awake': 409,\n",
              " 'online': 410,\n",
              " 'cry': 411,\n",
              " 'pain': 412,\n",
              " 'pics': 413,\n",
              " 'told': 414,\n",
              " 'fine': 415,\n",
              " 'loved': 416,\n",
              " 'breakfast': 417,\n",
              " 'boring': 418,\n",
              " 'facebook': 419,\n",
              " 'goes': 420,\n",
              " 'sunny': 421,\n",
              " 'person': 422,\n",
              " 'wake': 423,\n",
              " 'til': 424,\n",
              " 'seriously': 425,\n",
              " 'change': 426,\n",
              " 'open': 427,\n",
              " 'update': 428,\n",
              " 'minutes': 429,\n",
              " 'care': 430,\n",
              " 'called': 431,\n",
              " 'dude': 432,\n",
              " 'broke': 433,\n",
              " 'season': 434,\n",
              " 'pay': 435,\n",
              " 'lucky': 436,\n",
              " 'hungry': 437,\n",
              " 'gets': 438,\n",
              " 'concert': 439,\n",
              " 'asleep': 440,\n",
              " 'lmao': 441,\n",
              " 'bought': 442,\n",
              " 'june': 443,\n",
              " 'aw': 444,\n",
              " 'ass': 445,\n",
              " 'link': 446,\n",
              " 'site': 447,\n",
              " 'month': 448,\n",
              " '9': 449,\n",
              " 'anyway': 450,\n",
              " 'afternoon': 451,\n",
              " 'starting': 452,\n",
              " 'la': 453,\n",
              " 'bring': 454,\n",
              " 'shower': 455,\n",
              " 'crap': 456,\n",
              " 'favorite': 457,\n",
              " 'sister': 458,\n",
              " 'reply': 459,\n",
              " '100': 460,\n",
              " 'heading': 461,\n",
              " 'instead': 462,\n",
              " 'train': 463,\n",
              " 'fan': 464,\n",
              " 'drive': 465,\n",
              " 'walk': 466,\n",
              " 'study': 467,\n",
              " 'e': 468,\n",
              " 'sleeping': 469,\n",
              " 'xd': 470,\n",
              " 'yea': 471,\n",
              " 'text': 472,\n",
              " 'bye': 473,\n",
              " 'jealous': 474,\n",
              " 'rock': 475,\n",
              " 'red': 476,\n",
              " 'ice': 477,\n",
              " 'bout': 478,\n",
              " 'exams': 479,\n",
              " 'brother': 480,\n",
              " 'enjoying': 481,\n",
              " 'mad': 482,\n",
              " 'wonderful': 483,\n",
              " 'move': 484,\n",
              " 'high': 485,\n",
              " 'sore': 486,\n",
              " 'together': 487,\n",
              " 'hoping': 488,\n",
              " '0': 489,\n",
              " 'definitely': 490,\n",
              " 'finish': 491,\n",
              " 'mother': 492,\n",
              " 'running': 493,\n",
              " 'homework': 494,\n",
              " 'nite': 495,\n",
              " 'soooo': 496,\n",
              " 'sometimes': 497,\n",
              " 'problem': 498,\n",
              " 'congrats': 499,\n",
              " 'fail': 500,\n",
              " 'youtube': 501,\n",
              " 'l': 502,\n",
              " 'city': 503,\n",
              " 'fucking': 504,\n",
              " 'dead': 505,\n",
              " 'drink': 506,\n",
              " 'write': 507,\n",
              " '12': 508,\n",
              " 'email': 509,\n",
              " 'dear': 510,\n",
              " 'goin': 511,\n",
              " 'works': 512,\n",
              " 'ask': 513,\n",
              " 'means': 514,\n",
              " 'died': 515,\n",
              " 'sigh': 516,\n",
              " 'happened': 517,\n",
              " 'movies': 518,\n",
              " 'album': 519,\n",
              " 'suck': 520,\n",
              " 'laptop': 521,\n",
              " 'couple': 522,\n",
              " 'town': 523,\n",
              " 'boys': 524,\n",
              " 'church': 525,\n",
              " 'cut': 526,\n",
              " 'top': 527,\n",
              " 'tea': 528,\n",
              " 'eyes': 529,\n",
              " 'evening': 530,\n",
              " 'tour': 531,\n",
              " '20': 532,\n",
              " 'loves': 533,\n",
              " 'less': 534,\n",
              " 'perfect': 535,\n",
              " 'ipod': 536,\n",
              " 'weird': 537,\n",
              " 'ive': 538,\n",
              " 'comes': 539,\n",
              " 'set': 540,\n",
              " 'reason': 541,\n",
              " 'ppl': 542,\n",
              " 'happen': 543,\n",
              " 'months': 544,\n",
              " 'final': 545,\n",
              " 'gym': 546,\n",
              " 'nap': 547,\n",
              " 'water': 548,\n",
              " 'side': 549,\n",
              " 'songs': 550,\n",
              " 'dream': 551,\n",
              " 'ones': 552,\n",
              " 'dance': 553,\n",
              " 'meeting': 554,\n",
              " 'studying': 555,\n",
              " 'sound': 556,\n",
              " 'cat': 557,\n",
              " 'close': 558,\n",
              " 'loving': 559,\n",
              " 'cream': 560,\n",
              " 'test': 561,\n",
              " 'listen': 562,\n",
              " 'visit': 563,\n",
              " 'fall': 564,\n",
              " 'interesting': 565,\n",
              " 'tickets': 566,\n",
              " 'lil': 567,\n",
              " 'english': 568,\n",
              " 'list': 569,\n",
              " 'store': 570,\n",
              " 'mood': 571,\n",
              " 'seem': 572,\n",
              " 'fb': 573,\n",
              " 'agree': 574,\n",
              " 'second': 575,\n",
              " 'knew': 576,\n",
              " 'ate': 577,\n",
              " 'fast': 578,\n",
              " 'writing': 579,\n",
              " 'hang': 580,\n",
              " 'moment': 581,\n",
              " 'worst': 582,\n",
              " 'clean': 583,\n",
              " 'catch': 584,\n",
              " 'story': 585,\n",
              " '11': 586,\n",
              " 'ahh': 587,\n",
              " 'word': 588,\n",
              " 'turn': 589,\n",
              " 'chocolate': 590,\n",
              " 'broken': 591,\n",
              " 'pool': 592,\n",
              " 'smile': 593,\n",
              " 'awards': 594,\n",
              " 'air': 595,\n",
              " 'wishing': 596,\n",
              " 'page': 597,\n",
              " 'london': 598,\n",
              " 'ride': 599,\n",
              " 'saying': 600,\n",
              " 'hmm': 601,\n",
              " '1st': 602,\n",
              " 'via': 603,\n",
              " 'yep': 604,\n",
              " 'cleaning': 605,\n",
              " 'sleepy': 606,\n",
              " 'moving': 607,\n",
              " 'myspace': 608,\n",
              " 'worth': 609,\n",
              " 'xxx': 610,\n",
              " 'unfortunately': 611,\n",
              " 'short': 612,\n",
              " 'supposed': 613,\n",
              " 'driving': 614,\n",
              " 'forget': 615,\n",
              " 'black': 616,\n",
              " 'three': 617,\n",
              " 'past': 618,\n",
              " 'throat': 619,\n",
              " 'dreams': 620,\n",
              " 'pictures': 621,\n",
              " 'da': 622,\n",
              " 'wedding': 623,\n",
              " 'photo': 624,\n",
              " 'followfriday': 625,\n",
              " 'park': 626,\n",
              " 'star': 627,\n",
              " 'jonas': 628,\n",
              " 'mum': 629,\n",
              " 'sent': 630,\n",
              " 'sunshine': 631,\n",
              " 'g': 632,\n",
              " 'sat': 633,\n",
              " 'understand': 634,\n",
              " 'horrible': 635,\n",
              " 'plan': 636,\n",
              " 'tweeting': 637,\n",
              " 'em': 638,\n",
              " '15': 639,\n",
              " 'drinking': 640,\n",
              " 'k': 641,\n",
              " 'gave': 642,\n",
              " 'pick': 643,\n",
              " 'college': 644,\n",
              " 'team': 645,\n",
              " 'slow': 646,\n",
              " 'chance': 647,\n",
              " 'whats': 648,\n",
              " 'hugs': 649,\n",
              " 'account': 650,\n",
              " 'lady': 651,\n",
              " 'wonder': 652,\n",
              " 'worse': 653,\n",
              " 'bet': 654,\n",
              " 'moon': 655,\n",
              " 'mac': 656,\n",
              " 'date': 657,\n",
              " 'rather': 658,\n",
              " 'green': 659,\n",
              " 'doesnt': 660,\n",
              " 'easy': 661,\n",
              " 'cannot': 662,\n",
              " 'longer': 663,\n",
              " 'vote': 664,\n",
              " 'apparently': 665,\n",
              " 'updates': 666,\n",
              " 'bday': 667,\n",
              " 'mr': 668,\n",
              " 'hand': 669,\n",
              " 'holiday': 670,\n",
              " 'flu': 671,\n",
              " 'wtf': 672,\n",
              " 'scared': 673,\n",
              " 'special': 674,\n",
              " 'tuesday': 675,\n",
              " 'point': 676,\n",
              " 'parents': 677,\n",
              " 'plus': 678,\n",
              " 'flight': 679,\n",
              " 'spent': 680,\n",
              " 'band': 681,\n",
              " 'fell': 682,\n",
              " 'uk': 683,\n",
              " 'upset': 684,\n",
              " 'huge': 685,\n",
              " 'miley': 686,\n",
              " 'mtv': 687,\n",
              " 'due': 688,\n",
              " 'thx': 689,\n",
              " 'nope': 690,\n",
              " 'earlier': 691,\n",
              " 'spend': 692,\n",
              " 'plans': 693,\n",
              " 'ahhh': 694,\n",
              " 'body': 695,\n",
              " 'words': 696,\n",
              " 'line': 697,\n",
              " 'vacation': 698,\n",
              " 'bus': 699,\n",
              " 'hanging': 700,\n",
              " 'fair': 701,\n",
              " 'especially': 702,\n",
              " 'shows': 703,\n",
              " 'v': 704,\n",
              " 'shame': 705,\n",
              " 'beer': 706,\n",
              " 'lazy': 707,\n",
              " 'forever': 708,\n",
              " 'voice': 709,\n",
              " 'wondering': 710,\n",
              " 'worry': 711,\n",
              " 'website': 712,\n",
              " 'white': 713,\n",
              " 'message': 714,\n",
              " 'slept': 715,\n",
              " 'thursday': 716,\n",
              " 'answer': 717,\n",
              " 'david': 718,\n",
              " 'join': 719,\n",
              " 'sadly': 720,\n",
              " 'wear': 721,\n",
              " 'warm': 722,\n",
              " 'idk': 723,\n",
              " 'lets': 724,\n",
              " 'july': 725,\n",
              " 'cake': 726,\n",
              " 'thinks': 727,\n",
              " 'havent': 728,\n",
              " 'stomach': 729,\n",
              " 'support': 730,\n",
              " 'tom': 731,\n",
              " 'google': 732,\n",
              " 'fans': 733,\n",
              " 'figure': 734,\n",
              " 'safe': 735,\n",
              " 'learn': 736,\n",
              " 'different': 737,\n",
              " 'die': 738,\n",
              " 'looked': 739,\n",
              " 'inside': 740,\n",
              " 'bbq': 741,\n",
              " 'eye': 742,\n",
              " 'son': 743,\n",
              " 'episode': 744,\n",
              " 'camera': 745,\n",
              " 'meant': 746,\n",
              " 'chat': 747,\n",
              " 'small': 748,\n",
              " 'crying': 749,\n",
              " 'except': 750,\n",
              " 'number': 751,\n",
              " 'paper': 752,\n",
              " 'luv': 753,\n",
              " 'yummy': 754,\n",
              " 'met': 755,\n",
              " 'boyfriend': 756,\n",
              " 'sims': 757,\n",
              " 'liked': 758,\n",
              " 'shop': 759,\n",
              " 'officially': 760,\n",
              " 'pizza': 761,\n",
              " 'airport': 762,\n",
              " 'alright': 763,\n",
              " 'dress': 764,\n",
              " 'dm': 765,\n",
              " 'photos': 766,\n",
              " 'rainy': 767,\n",
              " 'project': 768,\n",
              " 'finals': 769,\n",
              " 'fix': 770,\n",
              " 'power': 771,\n",
              " 'garden': 772,\n",
              " 'twilight': 773,\n",
              " 'radio': 774,\n",
              " '2day': 775,\n",
              " 'absolutely': 776,\n",
              " 'f': 777,\n",
              " 'games': 778,\n",
              " 'worked': 779,\n",
              " 'graduation': 780,\n",
              " 'decided': 781,\n",
              " 'shirt': 782,\n",
              " 'apple': 783,\n",
              " 'shall': 784,\n",
              " 'blue': 785,\n",
              " 'hubby': 786,\n",
              " 'beat': 787,\n",
              " 'shoes': 788,\n",
              " 'kill': 789,\n",
              " 'lonely': 790,\n",
              " 'felt': 791,\n",
              " 'save': 792,\n",
              " 'proud': 793,\n",
              " 'kid': 794,\n",
              " 'laugh': 795,\n",
              " 'exciting': 796,\n",
              " 'road': 797,\n",
              " 'cd': 798,\n",
              " 'tummy': 799,\n",
              " 'bike': 800,\n",
              " 'brothers': 801,\n",
              " 'wit': 802,\n",
              " 'starts': 803,\n",
              " 'hmmm': 804,\n",
              " 'hug': 805,\n",
              " 'hospital': 806,\n",
              " 'played': 807,\n",
              " 'chicken': 808,\n",
              " 'cos': 809,\n",
              " 'wine': 810,\n",
              " 'card': 811,\n",
              " 'woo': 812,\n",
              " 'needed': 813,\n",
              " 'gorgeous': 814,\n",
              " 'exactly': 815,\n",
              " 'yup': 816,\n",
              " 'front': 817,\n",
              " 'babe': 818,\n",
              " 'lame': 819,\n",
              " 'feet': 820,\n",
              " 'books': 821,\n",
              " 'annoying': 822,\n",
              " 'keeps': 823,\n",
              " 'xoxo': 824,\n",
              " 'wednesday': 825,\n",
              " 'hates': 826,\n",
              " 'goodbye': 827,\n",
              " 'ouch': 828,\n",
              " 'packing': 829,\n",
              " 'wishes': 830,\n",
              " 'sign': 831,\n",
              " 'near': 832,\n",
              " 'taken': 833,\n",
              " 'french': 834,\n",
              " 'service': 835,\n",
              " 'scary': 836,\n",
              " 'bro': 837,\n",
              " 'club': 838,\n",
              " 'case': 839,\n",
              " 'fact': 840,\n",
              " 'jus': 841,\n",
              " 'happens': 842,\n",
              " 'behind': 843,\n",
              " 'business': 844,\n",
              " 'turned': 845,\n",
              " 'order': 846,\n",
              " 'question': 847,\n",
              " 'isnt': 848,\n",
              " 'realized': 849,\n",
              " 'gettin': 850,\n",
              " 'yo': 851,\n",
              " 'living': 852,\n",
              " 'mothers': 853,\n",
              " 'sis': 854,\n",
              " 'j': 855,\n",
              " 'knows': 856,\n",
              " 'cup': 857,\n",
              " 'share': 858,\n",
              " 'pass': 859,\n",
              " 'walking': 860,\n",
              " 'drunk': 861,\n",
              " 'everybody': 862,\n",
              " 'relaxing': 863,\n",
              " 'clothes': 864,\n",
              " 'download': 865,\n",
              " 'hahah': 866,\n",
              " '2nd': 867,\n",
              " 'killing': 868,\n",
              " 'mail': 869,\n",
              " 'whatever': 870,\n",
              " 'waking': 871,\n",
              " 'app': 872,\n",
              " 'sold': 873,\n",
              " 'giving': 874,\n",
              " 'vegas': 875,\n",
              " 'wife': 876,\n",
              " 'minute': 877,\n",
              " 'touch': 878,\n",
              " 'company': 879,\n",
              " 'film': 880,\n",
              " 'along': 881,\n",
              " 'although': 882,\n",
              " 'box': 883,\n",
              " 'random': 884,\n",
              " 'self': 885,\n",
              " 'revision': 886,\n",
              " 'lose': 887,\n",
              " 'alot': 888,\n",
              " 'web': 889,\n",
              " 'enjoyed': 890,\n",
              " 'single': 891,\n",
              " 'videos': 892,\n",
              " 'fantastic': 893,\n",
              " 'sit': 894,\n",
              " 'round': 895,\n",
              " 'lakers': 896,\n",
              " 'fly': 897,\n",
              " 'guitar': 898,\n",
              " 'terrible': 899,\n",
              " 'version': 900,\n",
              " 'nights': 901,\n",
              " 'comment': 902,\n",
              " 'asked': 903,\n",
              " 'interview': 904,\n",
              " 'ahead': 905,\n",
              " 'posted': 906,\n",
              " 'singing': 907,\n",
              " 'huh': 908,\n",
              " 'hun': 909,\n",
              " 'lately': 910,\n",
              " 'indeed': 911,\n",
              " 'bitch': 912,\n",
              " 'gosh': 913,\n",
              " 'passed': 914,\n",
              " 'mins': 915,\n",
              " 'disappointed': 916,\n",
              " 'peace': 917,\n",
              " 'aint': 918,\n",
              " 'hangover': 919,\n",
              " 'light': 920,\n",
              " 'eh': 921,\n",
              " 'dark': 922,\n",
              " 'bummed': 923,\n",
              " 'bar': 924,\n",
              " 'plane': 925,\n",
              " 'upload': 926,\n",
              " 'vip': 927,\n",
              " 'ohh': 928,\n",
              " 'daughter': 929,\n",
              " 'dying': 930,\n",
              " 'headed': 931,\n",
              " 'usually': 932,\n",
              " 'history': 933,\n",
              " 'staying': 934,\n",
              " 'completely': 935,\n",
              " 'mommy': 936,\n",
              " 'dvd': 937,\n",
              " 'hotel': 938,\n",
              " 'death': 939,\n",
              " 'country': 940,\n",
              " 'fingers': 941,\n",
              " 'freaking': 942,\n",
              " 'worried': 943,\n",
              " 'deal': 944,\n",
              " 'fml': 945,\n",
              " 'nobody': 946,\n",
              " 'ran': 947,\n",
              " 'quick': 948,\n",
              " 'currently': 949,\n",
              " 'fat': 950,\n",
              " 'changed': 951,\n",
              " 'shoot': 952,\n",
              " 'traffic': 953,\n",
              " 'serious': 954,\n",
              " 'yum': 955,\n",
              " 'bloody': 956,\n",
              " '24': 957,\n",
              " 'somewhere': 958,\n",
              " 'awful': 959,\n",
              " 'art': 960,\n",
              " 'bb': 961,\n",
              " 'sing': 962,\n",
              " 'pink': 963,\n",
              " 'cook': 964,\n",
              " 'wearing': 965,\n",
              " 'caught': 966,\n",
              " 'dang': 967,\n",
              " 'hold': 968,\n",
              " 'coz': 969,\n",
              " 'camp': 970,\n",
              " 'cousin': 971,\n",
              " 'nick': 972,\n",
              " 'extra': 973,\n",
              " 'door': 974,\n",
              " 'low': 975,\n",
              " 'nearly': 976,\n",
              " 'exhausted': 977,\n",
              " 'profile': 978,\n",
              " 'pissed': 979,\n",
              " 'others': 980,\n",
              " 'men': 981,\n",
              " 'nyc': 982,\n",
              " 'cheese': 983,\n",
              " '50': 984,\n",
              " 'sexy': 985,\n",
              " 'blood': 986,\n",
              " 'itunes': 987,\n",
              " 'dunno': 988,\n",
              " 'chillin': 989,\n",
              " 'ff': 990,\n",
              " 'ooh': 991,\n",
              " 'blah': 992,\n",
              " 'spending': 993,\n",
              " 'fixed': 994,\n",
              " 'pc': 995,\n",
              " 'watchin': 996,\n",
              " 'daddy': 997,\n",
              " 'tweetdeck': 998,\n",
              " 'fam': 999,\n",
              " 'matter': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgeKp90sM58e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "db2e2723-492b-4ce9-a507-ba6a41838d0a"
      },
      "source": [
        "# De texto para token\n",
        "for x,y in zip(data.text[20:22], sequences_test):\n",
        "  print('{}. --> {}.'.format(x,y))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "day get much done. --> [694, 38, 96].\n",
            "one friend called asked meet mid valley today time sigh. --> [110, 138, 1706, 25597, 24].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vuf9vTWYA1Cl",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<hr>\n",
        "<br>\n",
        "\n",
        "\n",
        "### Embedding - Glove \n",
        "\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PijwZmcmMedG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "5f3ec379-0892-44a1-b4e2-750ff81c7c1a"
      },
      "source": [
        "# Word Embedding at Stanford\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-31 01:11:15--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-08-31 01:11:16--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-08-31 01:11:16--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.1’\n",
            "\n",
            "glove.6B.zip.1      100%[===================>] 822.24M  2.15MB/s    in 6m 29s  \n",
            "\n",
            "2020-08-31 01:17:46 (2.11 MB/s) - ‘glove.6B.zip.1’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: \n",
            "error:  invalid response [{ENTER}]\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: \n",
            "error:  invalid response [{ENTER}]\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: \n",
            "error:  invalid response [{ENTER}]\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: \n",
            "error:  invalid response [{ENTER}]\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: glove.6B.50d.txt        \n",
            "replace glove.6B.100d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace glove.6B.200d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace glove.6B.300d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ShQ-dGtQrXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Glove Embedding\n",
        "GLOVE_EMB = '/content/glove.6B.300d.txt'\n",
        "EMBEDDING_DIM = 300 "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICCkmxMH0wkq",
        "colab_type": "text"
      },
      "source": [
        "calculamos um índice de mapeamento de palavras para embeddings conhecidos, analisando o despejo de dados de embeddings pré-treinados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iJ9giop4RYt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e7e737d-3ab7-4912-d138-d2b13b0b94c2"
      },
      "source": [
        "# preparing Embedding \n",
        "\n",
        "embeddings_index = {}\n",
        "\n",
        "f = open(GLOVE_EMB)\n",
        "\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Encontrado {} vetores de palavras.'.format(len(embeddings_index)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encontrado 400000 vetores de palavras.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do7LCzzU01zh",
        "colab_type": "text"
      },
      "source": [
        "podemos aproveitar nosso embedding_index dicionário e nosso word_index para calcular nossa matriz de incorporação.\n",
        "\n",
        "\n",
        "* Criando Matrix de Embedding (Glove) \n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJvCzDIb02IU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz2oG0J9A9nw",
        "colab_type": "text"
      },
      "source": [
        "Carregamos essa matriz de incorporação (Embedding Matrix) em uma Embedding camada. Observe que definimos <b>trainable=False</b> para evitar que os pesos sejam atualizados durante o treinamento.\n",
        "\n",
        "\n",
        "* trainable definido como true, os pesos seriam atualizados do modelo Glove\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egF7ezAm1xjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Embedding layer (Glove)\n",
        "\n",
        "embedding_layer = Embedding(vocab_size,\n",
        "                            EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=max_sequence_length,\n",
        "                            trainable=False)\n",
        "\n",
        "\n",
        "\n",
        "# Embedding layer (Not pre-trained)\n",
        "\"\"\"\n",
        "embedding_layer = Embedding(vocab_size,\n",
        "                            EMBEDDING_DIM,\n",
        "                            input_length=max_sequence_length)\"\"\""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIesQ5qDGKf0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "a2dcf459-7fa4-4749-c2a1-769d8ee9b40a"
      },
      "source": [
        "# LSTM \n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=max_sequence_length))\n",
        "model.add(embedding_layer)\n",
        "model.add(SpatialDropout1D(0.20))\n",
        "model.add(LSTM(units=64, recurrent_dropout=0.20))\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "model.add(Dropout(0.20))\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 50, 300)           79973400  \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_3 (Spatial (None, 50, 300)           0         \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 64)                93440     \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 512)               33280     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 80,363,289\n",
            "Trainable params: 389,889\n",
            "Non-trainable params: 79,973,400\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIW5PM5qG1Fm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "c04e6d1c-07a4-4062-d6be-f1492c7ea2f1"
      },
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "model.compile(optimizer=Adam(0.001),\n",
        "              loss=BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=1024,\n",
        "                    epochs=5,\n",
        "                    validation_data=(X_test, y_test))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1094/1094 [==============================] - 1079s 986ms/step - loss: 0.5233 - accuracy: 0.7371 - val_loss: 0.4857 - val_accuracy: 0.7647\n",
            "Epoch 2/5\n",
            "1094/1094 [==============================] - 1077s 984ms/step - loss: 0.4882 - accuracy: 0.7628 - val_loss: 0.4739 - val_accuracy: 0.7739\n",
            "Epoch 3/5\n",
            "1094/1094 [==============================] - 1075s 983ms/step - loss: 0.4776 - accuracy: 0.7693 - val_loss: 0.4659 - val_accuracy: 0.7770\n",
            "Epoch 4/5\n",
            "1094/1094 [==============================] - 1077s 984ms/step - loss: 0.4714 - accuracy: 0.7730 - val_loss: 0.4610 - val_accuracy: 0.7799\n",
            "Epoch 5/5\n",
            "1094/1094 [==============================] - 1074s 982ms/step - loss: 0.4669 - accuracy: 0.7762 - val_loss: 0.4647 - val_accuracy: 0.7812\n",
            "CPU times: user 2h 42min 55s, sys: 8min, total: 2h 50min 55s\n",
            "Wall time: 1h 29min 48s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDZDiIn_j0Dj",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<hr>\n",
        "<hr>\n",
        "<br>"
      ]
    }
  ]
}